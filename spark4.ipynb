{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOINS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bildiğimiz gibi çok büyük veri setleri üzerinde çalışırken bizim için en maliyetli işlemlerden biri join işlemleridir.Bu kısımda join işlemlerinin spark üzerinde nasıl çalıştırıldığına ve kullanılacağına bakacağız.Öncelikle çok fazla join çeşidi var ama zaten biri diğerinin laciverti,daha çok biz büyük verilerde ki join işemlerinin bir clusterın üzerinde nasıl çalışırılacağına bakacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Öncelikle join bildiğiniz üzere şartlı kartezyen çarpım olarak anlatılabilir.yani iki veri setini biribiri ile uygun olan bir veya daha fazla şarta göre birleştirme diyebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "person=spark.createDataFrame\\\n",
    "([(0,\"Abdullah \",0,[100])\\\n",
    " ,(1,\"Harun \",1,[500,250,100])\\\n",
    " ,(2,\"Omer \",1,[250,100])])\\\n",
    ".toDF(\"id\",\"name\",\"graduateProgram\",\"spark program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "graduateProgram=spark.createDataFrame\\\n",
    "([(0,\"Master\",\"School of Information\",\"UC Berkeley\")\\\n",
    " ,(2,\"Master\",\"EECS\",\"UC Berkeley\")\\\n",
    " ,(1,\"PhD\",\"EECS\",\"UC Berkeley\")])\\\n",
    " .toDF(\"id\",\"degree\",\"department\",\"school\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkStatus=spark.createDataFrame\\\n",
    "([(500,\"Vice President\"),(250,\"PMC Member\"),(100,\"Contributor\")]).toDF(\"id\",\"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------------+---------------+\n",
      "| id|     name|graduateProgram|  spark program|\n",
      "+---+---------+---------------+---------------+\n",
      "|  0|Abdullah |              0|          [100]|\n",
      "|  1|   Harun |              1|[500, 250, 100]|\n",
      "|  2|    Omer |              1|     [250, 100]|\n",
      "+---+---------+---------------+---------------+\n",
      "\n",
      "+---+------+--------------------+-----------+\n",
      "| id|degree|          department|     school|\n",
      "+---+------+--------------------+-----------+\n",
      "|  0|Master|School of Informa...|UC Berkeley|\n",
      "|  2|Master|                EECS|UC Berkeley|\n",
      "|  1|   PhD|                EECS|UC Berkeley|\n",
      "+---+------+--------------------+-----------+\n",
      "\n",
      "+---+--------------+\n",
      "| id|        status|\n",
      "+---+--------------+\n",
      "|500|Vice President|\n",
      "|250|    PMC Member|\n",
      "|100|   Contributor|\n",
      "+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.createOrReplaceGlobalTempView(\"person\")\n",
    "graduateProgram.createOrReplaceGlobalTempView(\"graduateProgram\")\n",
    "sparkStatus.createOrReplaceGlobalTempView(\"sparkStatus\")\n",
    "person.select(\"*\").show()\n",
    "graduateProgram.select(\"*\").show()\n",
    "sparkStatus.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi yukarıda join işlemleri için kullancağımız veri setlerini hazırladık ve hepsini birer temp view haline getirip direk   sql sorguları içinde müsait hale getirmiş olduk.\n",
    "<p> Aşağıda ise görüdğünüz gibi join işlemlerinin basitce nasıl kullanıldığını görmüş olduk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------------+---------------+---+------+--------------------+-----------+\n",
      "| id|     name|graduateProgram|  spark program| id|degree|          department|     school|\n",
      "+---+---------+---------------+---------------+---+------+--------------------+-----------+\n",
      "|  0|Abdullah |              0|          [100]|  0|Master|School of Informa...|UC Berkeley|\n",
      "|  1|   Harun |              1|[500, 250, 100]|  1|   PhD|                EECS|UC Berkeley|\n",
      "|  2|    Omer |              1|     [250, 100]|  1|   PhD|                EECS|UC Berkeley|\n",
      "+---+---------+---------------+---------------+---+------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#INNER JOIN\n",
    "joinExpression=person[\"graduateProgram\"]==graduateProgram[\"id\"]\n",
    "person.join(graduateProgram,joinExpression).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---------------+---------------+---+------+--------------------+-----------+\n",
      "|  id|     name|graduateProgram|  spark program| id|degree|          department|     school|\n",
      "+----+---------+---------------+---------------+---+------+--------------------+-----------+\n",
      "|   0|Abdullah |              0|          [100]|  0|Master|School of Informa...|UC Berkeley|\n",
      "|   1|   Harun |              1|[500, 250, 100]|  1|   PhD|                EECS|UC Berkeley|\n",
      "|   2|    Omer |              1|     [250, 100]|  1|   PhD|                EECS|UC Berkeley|\n",
      "|null|     null|           null|           null|  2|Master|                EECS|UC Berkeley|\n",
      "+----+---------+---------------+---------------+---+------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#OUTER \n",
    "jointype=\"outer\"\n",
    "person.join(graduateProgram,joinExpression,jointype).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+-----------+----+---------+---------------+---------------+\n",
      "| id|degree|          department|     school|  id|     name|graduateProgram|  spark program|\n",
      "+---+------+--------------------+-----------+----+---------+---------------+---------------+\n",
      "|  0|Master|School of Informa...|UC Berkeley|   0|Abdullah |              0|          [100]|\n",
      "|  1|   PhD|                EECS|UC Berkeley|   1|   Harun |              1|[500, 250, 100]|\n",
      "|  1|   PhD|                EECS|UC Berkeley|   2|    Omer |              1|     [250, 100]|\n",
      "|  2|Master|                EECS|UC Berkeley|null|     null|           null|           null|\n",
      "+---+------+--------------------+-----------+----+---------+---------------+---------------+\n",
      "\n",
      "+----+---------+---------------+---------------+---+------+--------------------+-----------+\n",
      "|  id|     name|graduateProgram|  spark program| id|degree|          department|     school|\n",
      "+----+---------+---------------+---------------+---+------+--------------------+-----------+\n",
      "|   0|Abdullah |              0|          [100]|  0|Master|School of Informa...|UC Berkeley|\n",
      "|   1|   Harun |              1|[500, 250, 100]|  1|   PhD|                EECS|UC Berkeley|\n",
      "|   2|    Omer |              1|     [250, 100]|  1|   PhD|                EECS|UC Berkeley|\n",
      "|null|     null|           null|           null|  2|Master|                EECS|UC Berkeley|\n",
      "+----+---------+---------------+---------------+---+------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LEFT-RIGHT OUTER JOIN\n",
    "jointype=\"left_outer\"\n",
    "graduateProgram.join(person,joinExpression,jointype).show()\n",
    "jointype=\"right_outer\"\n",
    "person.join(graduateProgram,joinExpression,jointype).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+-----------+\n",
      "| id|degree|          department|     school|\n",
      "+---+------+--------------------+-----------+\n",
      "|  0|Master|School of Informa...|UC Berkeley|\n",
      "|  1|   PhD|                EECS|UC Berkeley|\n",
      "+---+------+--------------------+-----------+\n",
      "\n",
      "+---+------+----------+-----------+\n",
      "| id|degree|department|     school|\n",
      "+---+------+----------+-----------+\n",
      "|  2|Master|      EECS|UC Berkeley|\n",
      "+---+------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Left Semi LeftAnti\n",
    "jointype=\"left_semi\"\n",
    "graduateProgram.join(person,joinExpression,jointype).show()\n",
    "jointype=\"left_anti\"\n",
    "graduateProgram.join(person,joinExpression,jointype).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+-----------+---+---------+---------------+---------------+\n",
      "| id|degree|          department|     school| id|     name|graduateProgram|  spark program|\n",
      "+---+------+--------------------+-----------+---+---------+---------------+---------------+\n",
      "|  0|Master|School of Informa...|UC Berkeley|  0|Abdullah |              0|          [100]|\n",
      "|  1|   PhD|                EECS|UC Berkeley|  1|   Harun |              1|[500, 250, 100]|\n",
      "|  1|   PhD|                EECS|UC Berkeley|  2|    Omer |              1|     [250, 100]|\n",
      "+---+------+--------------------+-----------+---+---------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Natural Joins-Cross joins\n",
    "jointype=\"cross\"\n",
    "graduateProgram.join(person,joinExpression,jointype).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark cluster üzerinde çalışırken dikkat etmemiz gereken diğer bir husus ise spark join işlemleri için cluster içerisinde nodelar arasında gerekli veri alışverişini yapıyor ancak eğer çok çok büyük tablolar ile daha küçük ölçekterki tabloları join işlemine tabi tutuyorsak bu durumda spark küçük tabloyu tüm büyük veri setinin parçaları bulunan node'lara birer kopyasını gönderiyor ve join işlemini tamamlıyor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu kısımda kısaca spark üzerinde join nasıl yapılır onu görmüş olduk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>resource<b/>=https://github.com/databricks/spark-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
